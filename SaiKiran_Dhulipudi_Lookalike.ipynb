{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c11a61a0-4653-497a-99b4-d745c37ed840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\eCommerce_Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.chdir(\"C:/eCommerce_Project\")  # folder \n",
    "print(os.getcwd())  # Checking the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aaf3417-31d4-4a53-aebf-940e3546c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a090185a-7079-425b-92e0-eafec5b78a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Data:\n",
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "\n",
      "Products Data:\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "\n",
      "Transactions Data:\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067   2024-04-25 7:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Loading the datasets\n",
    "customers = pd.read_csv(\"Customers.csv\")\n",
    "products = pd.read_csv(\"Products.csv\")\n",
    "transactions = pd.read_csv(\"Transactions.csv\")\n",
    "\n",
    "# Checking the first few rows of each dataset\n",
    "print(\"Customers Data:\")\n",
    "print(customers.head())\n",
    "\n",
    "print(\"\\nProducts Data:\")\n",
    "print(products.head())\n",
    "\n",
    "print(\"\\nTransactions Data:\")\n",
    "print(transactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a80dd0-fad2-427b-9bdb-7ea28a642758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID      0\n",
      "CustomerName    0\n",
      "Region          0\n",
      "SignupDate      0\n",
      "dtype: int64\n",
      "ProductID      0\n",
      "ProductName    0\n",
      "Category       0\n",
      "Price          0\n",
      "dtype: int64\n",
      "TransactionID      0\n",
      "CustomerID         0\n",
      "ProductID          0\n",
      "TransactionDate    0\n",
      "Quantity           0\n",
      "TotalValue         0\n",
      "Price              0\n",
      "dtype: int64\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in the datasets\n",
    "print(customers.isnull().sum())\n",
    "print(products.isnull().sum())\n",
    "print(transactions.isnull().sum())\n",
    "\n",
    "# Checking for duplicate rows\n",
    "print(customers.duplicated().sum())\n",
    "print(products.duplicated().sum())\n",
    "print(transactions.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13346dd8-e73b-4f5f-aa7a-82bd6e54140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates handling\n",
    "customers.drop_duplicates(inplace=True)\n",
    "products.drop_duplicates(inplace=True)\n",
    "transactions.drop_duplicates(inplace=True)\n",
    "\n",
    "# Handling missing values (impute or drop)\n",
    "customers.ffill(inplace=True)  # Forward fill for customer data\n",
    "products.ffill(inplace=True)   # Forward fill for product data\n",
    "transactions.fillna(0, inplace=True)  # Impute missing transaction data with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7c783e-c874-4faf-9228-46a9e8ea78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging customer data with transaction data\n",
    "transactions_with_customers = pd.merge(transactions, customers, on='CustomerID', how='left')\n",
    "\n",
    "# Aggregating transaction data by customer (total spending, total quantity purchased, etc.)\n",
    "customer_summary = transactions_with_customers.groupby('CustomerID').agg(\n",
    "    total_spent=('TotalValue', 'sum'),\n",
    "    total_quantity=('Quantity', 'sum'),\n",
    "    avg_spent_per_purchase=('TotalValue', 'mean'),\n",
    "    num_purchases=('TransactionID', 'nunique'),\n",
    ").reset_index()\n",
    "\n",
    "# Merging with customer demographic data\n",
    "customer_summary = pd.merge(customer_summary, customers[['CustomerID', 'Region']], on='CustomerID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa3a66d-0043-4526-af76-d27153d1214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID LookalikeCustomerID  SimilarityScore\n",
      "0      C0001               C0164         0.996031\n",
      "1      C0001               C0103         0.981548\n",
      "2      C0001               C0069         0.963423\n",
      "3      C0002               C0029         0.999525\n",
      "4      C0002               C0031         0.997756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Sample customer summary DataFrame (replace with actual data)\n",
    "# customer_summary = pd.read_csv(\"customer_summary.csv\")  # Replace with your actual DataFrame\n",
    "\n",
    "# Select features for similarity calculation\n",
    "similarity_features = customer_summary[['total_spent', 'total_quantity', 'avg_spent_per_purchase', 'num_purchases']]\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "similarity_features_scaled = scaler.fit_transform(similarity_features)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(similarity_features_scaled)\n",
    "\n",
    "# Convert cosine similarity to DataFrame for better visualization\n",
    "similarity_df = pd.DataFrame(cosine_sim, index=customer_summary['CustomerID'], columns=customer_summary['CustomerID'])\n",
    "\n",
    "# For each customer (C0001 - C0020), find the top 3 lookalikes\n",
    "lookalike_results = {}\n",
    "\n",
    "# Loop through first 20 customers\n",
    "for customer_id in customer_summary['CustomerID'].head(20):\n",
    "    similar_customers = similarity_df[customer_id].nlargest(4).iloc[1:]  # Exclude the customer itself\n",
    "    lookalike_results[customer_id] = [(x[0], x[1]) for x in zip(similar_customers.index, similar_customers.values)]\n",
    "\n",
    "# Flatten the lookalike results into a list of tuples for DataFrame\n",
    "flattened_results = []\n",
    "for customer_id, lookalikes in lookalike_results.items():\n",
    "    for lookalike in lookalikes:\n",
    "        flattened_results.append([customer_id, lookalike[0], lookalike[1]])\n",
    "\n",
    "# Creating the DataFrame for lookalike results\n",
    "lookalike_df = pd.DataFrame(flattened_results, columns=['CustomerID', 'LookalikeCustomerID', 'SimilarityScore'])\n",
    "\n",
    "# Preview the first few rows of lookalike results\n",
    "print(lookalike_df.head())  # To see the first few lookalike results\n",
    "\n",
    "# Save the results to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d615c8-f8a4-45d6-b5bd-6633ddd702c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
